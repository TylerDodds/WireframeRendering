// SPDX-License-Identifier: MIT
// SPDX-FileCopyrightText: © 2022 Tyler Dodds

#ifndef WIREFRAME_GEOMETRY_INCLUDED
#define WIREFRAME_GEOMETRY_INCLUDED

#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/GeometricTools.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl"
#include "WireframeUtil.hlsl"

#if defined(SHADER_API_GLCORE) || defined(SHADER_API_GLES) || defined(SHADER_API_GLES3)
#else
#define WIREFRAME_CAN_USE_NOPERSPECTIVE
#endif

#if defined(WIREFRAME_USE_OBJECT_NORMALS) && defined(WIREFRAME_WORLD)
#define WIREFRAME_NEEDS_OBJECT_NORMALS
#endif

#if !defined(_WIREFRAME_CONTOUR_EDGES_NOTIMPORTED)
#define WIREFRAME_NEEDS_FACE_NORMALS
#endif

CBUFFER_START(UnityPerMaterial)
uniform float _Width;
uniform float _OvershootLength;
uniform float _FalloffWidth;
uniform float _DashLength;
uniform float _EmptyLength;
uniform float _TexLength;
uniform float _DepthFadeDistance;
uniform float4 _EdgeColor;
//Note: don't #ifdef out properties here as SRP batcher can not handle different layouts.
uniform float _WireframeCutoff;
uniform float _InFrontDepthCutoff;
uniform float4 _NdcMinMaxCutoffForWidthAndAlpha;
CBUFFER_END

#ifdef WIREFRAME_TEXTURE
TEXTURE2D(_WireframeTex);
SamplerState sampler_linear_repeat;
#endif

// This structure is created by the renderer and passed to the Vertex function
// It holds data stored on the model, per vertex
struct Attributes 
{
	float4 positionOS   : POSITION; // Position in object space
	#if defined(WIREFRAME_NEEDS_OBJECT_NORMALS)
	float3 normalOS     : NORMAL;
	#endif
	#if defined(WIREFRAME_NEEDS_FACE_NORMALS)
	float3 faceNormalOS : TEXCOORD0;
	#endif
};

struct AttributesQuad
{
	float4 positionOS   : POSITION; // Position in object space
	float3 otherPositionOS : TEXCOORD1;
#if defined(WIREFRAME_NEEDS_OBJECT_NORMALS)
	float3 normalOS     : NORMAL;
#endif
#if defined(WIREFRAME_NEEDS_FACE_NORMALS)
	float3 faceNormalOS : TEXCOORD0;
	float3 otherFaceNormalOS : TEXCOORD2;
#endif
};

// This structure is generated by the vertex function and passed to the geometry function
struct VertexOutput 
{
	float3 positionVS   : TEXCOORD0; // Position in view space
	#if defined(WIREFRAME_NEEDS_OBJECT_NORMALS)
	float3 normalVS     : TEXCOORD1;
	#endif
	#if defined(WIREFRAME_NEEDS_FACE_NORMALS)
	float3 faceNormalVS : TEXCOORD1;
	#endif
};

// This structure is generated by the geometry function and passed to the fragment function
// Remember the renderer averages these values between the three points on the triangle 
struct GeometryOutput 
{
	float4 positionCS  : SV_POSITION; // Position in clip space
#ifdef  WIREFRAME_CAN_USE_NOPERSPECTIVE
	#if defined(WIREFRAME_WORLD)
	float3 uvAndLengthScale : TEXCOORD0; // uv coordinate on the generated segment quad 
	#else
	noperspective float3 uvAndLengthScale : TEXCOORD0; // uv coordinate on the generated segment quad, interpolated in screen space without perspective
	#endif
#else
	float4 uvLengthScaleAndClipW : TEXCOORD0;//uv coordinate on the generated segment quad, length of segment, and clip W to get around noperspective seemingly not working in some cases like OpenGL ES 3.0
	
#endif
	float3 spineVS : TEXCOORD1;
	
};

// Vertex functions

float3 NormalOSToVS(float3 normalOS)
{
	return TransformWorldToViewDir(GetVertexNormalInputs(normalOS).normalWS);
}

float3 FaceNormalOSToVS(float3 faceNormalOS)
{
	return TransformWorldToViewDir(TransformObjectToWorldNormal(faceNormalOS, false));
}

VertexOutput Vertex(Attributes input) 
{
	// Initialize an output struct
	VertexOutput output = (VertexOutput)0;

	// Use this URP function to convert position to view space
	VertexPositionInputs vertexInput = GetVertexPositionInputs(input.positionOS.xyz);
	output.positionVS = vertexInput.positionVS;
	#if defined(WIREFRAME_NEEDS_OBJECT_NORMALS)
	output.normalVS = NormalOSToVS(input.normalOS);
	#endif
	#if defined(WIREFRAME_NEEDS_FACE_NORMALS)
	output.faceNormalVS = FaceNormalOSToVS(input.faceNormalOS);
	#endif
	return output;
}

// Geometry functions

GeometryOutput SetupVertexVS(float3 positionVS, float2 uv, float lengthScale, float3 spineVS)
{
	// Setup an output struct
	GeometryOutput output = (GeometryOutput)0;
	output.positionCS = TransformWViewToHClip(positionVS);
	output.spineVS = spineVS;
#ifdef WIREFRAME_CAN_USE_NOPERSPECTIVE
	output.uvAndLengthScale = float3(uv, lengthScale);
#else
	output.uvLengthScaleAndClipW = float4(uv, lengthScale, 1);
#endif
	return output;
}

GeometryOutput SetupVertexSS(float2 positionSS, float2 uv, float lengthScale, float3 spineVS, float4 clip)
{
	float4 scaledScreenParams = GetScaledScreenParams();
	float4 positionClip = ComputeClipSpacePosition(positionSS / scaledScreenParams.xy, clip.z / clip.w) * clip.w;
	
	// Setup an output struct
	GeometryOutput output = (GeometryOutput)0;
	output.positionCS = positionClip;
	output.spineVS = spineVS;
	#ifdef WIREFRAME_CAN_USE_NOPERSPECTIVE
	output.uvAndLengthScale = float3(uv, lengthScale);
	#else
	output.uvLengthScaleAndClipW = float4(uv, lengthScale, 1) * clip.w;
	#endif

	return output;
}

//NB Similar to com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl
float3 ComputeNormalizedDeviceCoordinatesWithZFromPositionCS(float4 positionCS)
{
#if UNITY_UV_STARTS_AT_TOP
	positionCS.y = -positionCS.y;
#endif

	positionCS *= rcp(positionCS.w);
	positionCS.xy = positionCS.xy * 0.5 + 0.5;

	return positionCS.xyz;
}

//NB Similar to com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl, but without flipping sign of z.
float3 ComputeViewSpacePositionFromPositionCS(float4 positionCS, float4x4 invProjMatrix)
{
	float4 positionVS = mul(invProjMatrix, positionCS);
	return positionVS.xyz / positionVS.w;
}

float3 ClosestPointOnRay(float3 rayStart, float3 rayDir, float3 otherRayStart, float3 otherRayDir)
{
	//Letting the first ray be a + td, and the second being b + uc, we want to find the extremum point and solve for t to ensure the returned point is on the first ray, so the value of u is irrelevant.
	//Then letting D = b-a, D_c = dot(D, c), D_d = dot(D, d) and m = dot(c,d), then t = (D_d - D_c * m) / (1 - m^2).
	float3 D = otherRayStart - rayStart;
	float Dd = dot(D, rayDir);
	float Dc = dot(D, otherRayDir);
	float m = dot(rayDir, otherRayDir);
	float t = (Dd - Dc * m) / (1 - m * m);
	return rayStart + t * rayDir;
}

bool ClipToVS(inout float3 startVS, inout float3 endVS, inout float startV, inout float endV)
{
	bool clipped = false;
	float epsilon = -_ProjectionParams.y;//Near-clip plane
	float tVS = ((epsilon - startVS.z) / (endVS.z - startVS.z));//start + t * (end - start) = epsilon [z-component]
	bool endInFrontOfStartVS = endVS.z > startVS.z;
	if (startVS.z == endVS.z)
	{
		
	}
	else if (saturate(tVS) == tVS)//tVS is between 0 and 1
	{
		float3 intersectionVS = startVS * (1 - tVS) + endVS * tVS;
		float intersectionV = startV * (1 - tVS) + endV * tVS;
		if (endInFrontOfStartVS)
		{
			endV = intersectionV;
			endVS = intersectionVS;
		}
		else
		{
			startV = intersectionV;
			startVS = intersectionVS;
		}
	}
	else if (tVS > 1 && !endInFrontOfStartVS)
	{
		clipped = true;
	}
	else if (tVS < 0 && endInFrontOfStartVS)
	{
		clipped = true;
	}
	return clipped;
}

bool GeometryTransform(float3 startVS, float3 endVS,
#if defined(WIREFRAME_NEEDS_OBJECT_NORMALS)
	float3 normal0VS, float3 normal1VS,
#endif
#if defined(WIREFRAME_NEEDS_FACE_NORMALS)
	float3 faceNormal0VS, float3 faceNormal1VS,
#endif
	out float startU, out float endU, out float finalStartV, out float finalEndV, out float segmentScale, out float3 startSpineVS, out float3 endSpineVS,
#if !defined(WIREFRAME_WORLD)
	out float4 startSpineClip, out float4 endSpineClip, out float2 startRightSS, out float2 startLeftSS, out float2 endRightSS, out float2 endLeftSS
#else
	out float3 startRightVS, out float3 startLeftVS, out float3 endRightVS, out float3 endLeftVS
#endif
)
{
	startU = endU = finalStartV = finalEndV = segmentScale = 0;
	startSpineVS = endSpineVS = 0;
#if !defined(WIREFRAME_WORLD)
	startRightSS = startLeftSS = endRightSS = endLeftSS = 0;
	startSpineClip = endSpineClip = 0;
#else
	startRightVS = startLeftVS = endRightVS = endLeftVS = 0;
#endif

	//NB Subtract 0.5 from v parameter as simple method to try to eliminate crawling issues
	float startV = -0.5;
	float endV = 0.5;
	bool clipped = ClipToVS(startVS, endVS, startV, endV);
	if (clipped)
	{
		return false;
	}

	#if !defined(_WIREFRAME_CONTOUR_EDGES_NOTIMPORTED)
	bool isBoundaryEdge = !any(faceNormal0VS) && !any(faceNormal1VS);
	#if defined(_WIREFRAME_CONTOUR_EDGES_SHOWN)
	float3 centerVS = 0.5 * (startVS + endVS);
	bool isContourEdge = sign(dot(centerVS, faceNormal0VS) * dot(centerVS, faceNormal1VS)) < 0;
	if (!(isBoundaryEdge || isContourEdge))
	#else
	if (!isBoundaryEdge)
	#endif
	{
		return false;
	}
	#endif

#if defined(WIREFRAME_CLIP)
	startU = -_WireframeCutoff / _Width;
	endU = 1 - startU;
#else
	startU = 0;
	endU = 1;
#endif

#if !defined(WIREFRAME_WORLD)

	float4x4 viewToHClip = GetViewToHClipMatrix();
	float4 startClip = ComputeClipSpacePosition(startVS, viewToHClip);
	float4 endClip = ComputeClipSpacePosition(endVS, viewToHClip);
	float3 startNDC = ComputeNormalizedDeviceCoordinatesWithZFromPositionCS(startClip);
	float3 endNDC = ComputeNormalizedDeviceCoordinatesWithZFromPositionCS(endClip);

	float widthSS = _Width * 0.5;
	#if defined(WIREFRAME_CLIP)
	widthSS += _WireframeCutoff;
	#endif

	float4 scaledScreenParams = GetScaledScreenParams();
	float2 startSS = startNDC.xy * scaledScreenParams.xy;
	float2 endSS = endNDC.xy * scaledScreenParams.xy;

	float2 segmentDifferenceSS = endSS - startSS;
	float segmentLengthSS = length(segmentDifferenceSS);
	float segmentLengthSSInv = rcp(segmentLengthSS);
	float2 segmentDirSS = segmentDifferenceSS * segmentLengthSSInv;
	float2 segmentNormalSS = float2(segmentDirSS.y, -segmentDirSS.x);

	float segmentLengthScaleSS = segmentLengthSS / (endV - startV);

	#if defined(WIREFRAME_OVERSHOOT)

	startSS -= segmentDirSS * _OvershootLength;
	endSS += segmentDirSS * _OvershootLength;

	startLeftSS = startSS - segmentNormalSS * widthSS;
	startRightSS = startSS + segmentNormalSS * widthSS;
	endLeftSS = endSS - segmentNormalSS * widthSS;
	endRightSS = endSS + segmentNormalSS * widthSS;

	float overshootFraction = _OvershootLength * segmentLengthSSInv;
	float overshootStartV = startV - overshootFraction * (endV - startV);
	float overshootEndV = endV + overshootFraction * (endV - startV);

	//NB Note that using startNDC.z (without overshoot) will be wrong here, but since we don't know the actual depth, this is just needed to get the VS ray corresponding to the overshoot SS point
	float4 reprojectedStartClip = ComputeClipSpacePosition(startSS / scaledScreenParams.xy, startNDC.z);
	float4 reprojectedEndClip = ComputeClipSpacePosition(endSS / scaledScreenParams.xy, endNDC.z);
	float3 reprojectedStartVS = ComputeViewSpacePositionFromPositionCS(reprojectedStartClip, UNITY_MATRIX_I_P);
	float3 reprojectedEndVS = ComputeViewSpacePositionFromPositionCS(reprojectedEndClip, UNITY_MATRIX_I_P);
	float3 dirVS = SafeNormalize(endVS - startVS);

	float3 closestStartVS = ClosestPointOnRay(startVS, dirVS, float3(0, 0, 0), SafeNormalize(reprojectedStartVS));
	float3 closestEndVS = ClosestPointOnRay(startVS, dirVS, float3(0, 0, 0), SafeNormalize(reprojectedEndVS));

	clipped = ClipToVS(closestStartVS, closestEndVS, overshootStartV, overshootEndV);
	if (clipped)
	{
		return false;
	}

	float4 closestStartClip = TransformWViewToHClip(closestStartVS);
	float4 closestEndClip = TransformWViewToHClip(closestEndVS);

	segmentScale = segmentLengthScaleSS;
	finalStartV = overshootStartV;
	finalEndV = overshootEndV;
	startSpineVS = closestStartVS;
	endSpineVS = closestEndVS;
	startSpineClip = closestStartClip;
	endSpineClip = closestEndClip;

	#else
	startLeftSS = startSS - segmentNormalSS * widthSS;
	startRightSS = startSS + segmentNormalSS * widthSS;
	endLeftSS = endSS - segmentNormalSS * widthSS;
	endRightSS = endSS + segmentNormalSS * widthSS;

	segmentScale = segmentLengthScaleSS;
	finalStartV = startV;
	finalEndV = endV;
	startSpineVS = startVS;
	endSpineVS = endVS;
	startSpineClip = startClip;
	endSpineClip = endClip;

	#endif


#else
	float3 segmentDifferenceVS = endVS - startVS;
	float segmentLengthVS = length(segmentDifferenceVS);
	float segmentLengthInvVS = rcp(segmentLengthVS);
	float3 segmentDirVS = segmentDifferenceVS * segmentLengthInvVS;

	#if defined(WIREFRAME_USE_OBJECT_NORMALS)
	float3 normalVS = SafeNormalize((normal0VS + normal1VS) * 0.5);
	float3 binormalVS = SafeNormalize(cross(normalVS, segmentDirVS));
	#else
	float3 startViewDirVS = -SafeNormalize(startVS);
	float3 endViewDirVS = -SafeNormalize(endVS);
	float3 startBinormalVS = cross(startViewDirVS, segmentDirVS);
	float3 endBinormalVS = cross(endViewDirVS, segmentDirVS);
	float3 avgBinormalVS = SafeNormalize(startBinormalVS + endBinormalVS);
	float3 binormalVS = avgBinormalVS;
	#endif

	float widthWs = _Width * 0.5;
	#if defined(WIREFRAME_CLIP)
	widthWs += _WireframeCutoff;
	#endif

	#if defined(WIREFRAME_OVERSHOOT)
	startVS -= segmentDirVS * _OvershootLength;
	endVS += segmentDirVS * _OvershootLength;

	startLeftVS = startVS - binormalVS * widthWs;
	startRightVS = startVS + binormalVS * widthWs;
	endLeftVS = endVS - binormalVS * widthWs;
	endRightVS = endVS + binormalVS * widthWs;

	float vDifference = endV - startV;
	float vOvershoot = vDifference * _OvershootLength * segmentLengthInvVS;
	float startVWithOvershoot = startV - vOvershoot;
	float endVWithOvershoot = endV + vOvershoot;

	float origSegmentLengthVS = segmentLengthVS / vDifference;

	startSpineVS = startVS;
	endSpineVS = endVS;
	segmentScale = origSegmentLengthVS;
	finalStartV = startVWithOvershoot;
	finalEndV = endVWithOvershoot;

	#else
	startLeftVS = startVS - binormalVS * widthWs;
	startRightVS = startVS + binormalVS * widthWs;
	endLeftVS = endVS - binormalVS * widthWs;
	endRightVS = endVS + binormalVS * widthWs;

	float origSegmentLengthScaleVS = segmentLengthVS / (endV - startV);

	startSpineVS = startVS;
	endSpineVS = endVS;
	segmentScale = origSegmentLengthScaleVS;
	finalStartV = startV;
	finalEndV = endV;

	#endif

#endif

	return true;
}

// We create two triangles from one segment, so there will be 4 vertices
[maxvertexcount(4)]
void Geometry(line VertexOutput inputs[2], inout TriangleStream<GeometryOutput> outputStream)
{
#if !defined(WIREFRAME_WORLD)
	float startU, endU, finalStartV, finalEndV, segmentScale;
	float3 startSpineVS, endSpineVS;
	float4 startSpineClip, endSpineClip;
	float2 startRightSS, startLeftSS, endRightSS, endLeftSS;
	bool doOutput = GeometryTransform(inputs[0].positionVS, inputs[1].positionVS,
	#if defined(WIREFRAME_NEEDS_OBJECT_NORMALS)
		inputs[0].normalVS, inputs[1].normalVS,
	#endif
	#if defined(WIREFRAME_NEEDS_FACE_NORMALS)
		inputs[0].faceNormalVS, inputs[1].faceNormalVS,
	#endif
		startU, endU, finalStartV, finalEndV, segmentScale, startSpineVS, endSpineVS,
		startSpineClip, endSpineClip, startRightSS, startLeftSS, endRightSS, endLeftSS
		);

	if (doOutput)
	{
		outputStream.Append(SetupVertexSS(startRightSS, float2(endU, finalStartV), segmentScale, startSpineVS, startSpineClip));
		outputStream.Append(SetupVertexSS(startLeftSS, float2(startU, finalStartV), segmentScale, startSpineVS, startSpineClip));
		outputStream.Append(SetupVertexSS(endRightSS, float2(endU, finalEndV), segmentScale, endSpineVS, endSpineClip));
		outputStream.Append(SetupVertexSS(endLeftSS, float2(startU, finalEndV), segmentScale, endSpineVS, endSpineClip));
	}

#else
	float startU, endU, finalStartV, finalEndV, segmentScale;
	float3 startSpineVS, endSpineVS, startRightVS, startLeftVS, endRightVS, endLeftVS;
	bool doOutput = GeometryTransform(inputs[0].positionVS, inputs[1].positionVS,
#if defined(WIREFRAME_NEEDS_OBJECT_NORMALS)
		inputs[0].normalVS, inputs[1].normalVS,
#endif
#if defined(WIREFRAME_NEEDS_FACE_NORMALS)
		inputs[0].faceNormalVS, inputs[1].faceNormalVS,
#endif
		startU, endU, finalStartV, finalEndV, segmentScale, startSpineVS, endSpineVS,
		startRightVS, startLeftVS, endRightVS, endLeftVS
	);

	if (doOutput)
	{
		outputStream.Append(SetupVertexVS(startRightVS, float2(endU, finalStartV), segmentScale, startSpineVS));
		outputStream.Append(SetupVertexVS(startLeftVS, float2(startU, finalStartV), segmentScale, startSpineVS));
		outputStream.Append(SetupVertexVS(endRightVS, float2(endU, finalEndV), segmentScale, endSpineVS));
		outputStream.Append(SetupVertexVS(endLeftVS, float2(startU, finalEndV), segmentScale, endSpineVS));
	}
#endif
}

GeometryOutput VertexQuads(AttributesQuad input, uint vertexId : SV_VertexID)
{
	// Use this URP function to convert position to view space
	VertexPositionInputs vertexInput = GetVertexPositionInputs(input.positionOS.xyz);
	VertexPositionInputs otherVertexInput = GetVertexPositionInputs(input.otherPositionOS.xyz);
	bool isStart = vertexId % 2 == 0;
	bool isRight = (vertexId / 2) % 2 == 0;
	float3 positionVS = isStart ? vertexInput.positionVS : otherVertexInput.positionVS;
	float3 otherPositionVS = isStart ? otherVertexInput.positionVS : vertexInput.positionVS;
#if defined(WIREFRAME_NEEDS_OBJECT_NORMALS)
	float3 normalVS = NormalOSToVS(input.normalOS);//NB Since vertex normal is constant across a segment, we don't need to load the 'other' one.
#endif
#if defined(WIREFRAME_NEEDS_FACE_NORMALS)
	float3 faceNormalVS = FaceNormalOSToVS(isStart ? input.faceNormalOS : input.otherFaceNormalOS);
	float3 otherFaceNormalVS = FaceNormalOSToVS(isStart ? input.otherFaceNormalOS : input.faceNormalOS);
#endif

	GeometryOutput output = (GeometryOutput)0;

#if !defined(WIREFRAME_WORLD)
	float startU, endU, finalStartV, finalEndV, segmentScale;
	float3 startSpineVS, endSpineVS;
	float4 startSpineClip, endSpineClip;
	float2 startRightSS, startLeftSS, endRightSS, endLeftSS;
	bool doOutput = GeometryTransform(positionVS, otherPositionVS,
#if defined(WIREFRAME_NEEDS_OBJECT_NORMALS)
		normalVS, normalVS,
#endif
#if defined(WIREFRAME_NEEDS_FACE_NORMALS)
		faceNormalVS, otherFaceNormalVS,
#endif
		startU, endU, finalStartV, finalEndV, segmentScale, startSpineVS, endSpineVS,
		startSpineClip, endSpineClip, startRightSS, startLeftSS, endRightSS, endLeftSS
	);

	if (doOutput)
	{
		float2 vertexSS = isRight ? (isStart ? startRightSS : endRightSS) : (isStart ? startLeftSS : endLeftSS);
		float vertexU = isRight ? endU : startU;
		float vertexV = isStart ? finalStartV : finalEndV;
		float3 vertexSpineVS = isStart ? startSpineVS : endSpineVS;
		float4 vertexSpineClip = isStart ? startSpineClip : endSpineClip;
		output = SetupVertexSS(vertexSS, float2(vertexU, vertexV), segmentScale, vertexSpineVS, vertexSpineClip);
	}

#else
	float startU, endU, finalStartV, finalEndV, segmentScale;
	float3 startSpineVS, endSpineVS, startRightVS, startLeftVS, endRightVS, endLeftVS;
	bool doOutput = GeometryTransform(positionVS, otherPositionVS,
#if defined(WIREFRAME_NEEDS_OBJECT_NORMALS)
		normalVS, normalVS,
#endif
#if defined(WIREFRAME_NEEDS_FACE_NORMALS)
		faceNormalVS, otherFaceNormalVS,
#endif
		startU, endU, finalStartV, finalEndV, segmentScale, startSpineVS, endSpineVS,
		startRightVS, startLeftVS, endRightVS, endLeftVS
	);

	if (doOutput)
	{
		float3 vertexVS = isRight ? (isStart ? startRightVS : endRightVS) : (isStart ? startLeftVS : endLeftVS);
		float vertexU = isRight ? endU : startU;
		float vertexV = isStart ? finalStartV : finalEndV;
		float3 vertexSpineVS = isStart ? startSpineVS : endSpineVS;
		output = SetupVertexVS(vertexVS, float2(vertexU, vertexV), segmentScale, vertexSpineVS);
	}
#endif

	return output;
}

#ifdef PLATFORM_SUPPORT_GATHER
#else
SamplerState my_point_clamp_sampler;
#endif

// Fragment functions

// The SV_Target semantic tells the compiler that this function outputs the pixel color
float4 Fragment(GeometryOutput input) : SV_Target
{
	float4x4 viewToHClip = GetViewToHClipMatrix();
	float3 spineNDC = ComputeNormalizedDeviceCoordinatesWithZ(input.spineVS, viewToHClip);

	float2 ndcOutsideViewComponents = abs(2 * (spineNDC.xy - 0.5)) - 1;
	float ndcOutsideView = max(ndcOutsideViewComponents.x, ndcOutsideViewComponents.y);
	float outsideViewFactor = smoothstep(-0.01, 0.01, ndcOutsideView);
	
	#ifdef PLATFORM_SUPPORT_GATHER
	float4 rawDepthGather = GATHER_RED_TEXTURE2D(_CameraDepthTexture, sampler_CameraDepthTexture, spineNDC.xy);
	#else
	float4 scaledScreenParams = GetScaledScreenParams();
	float2 halfTexel = (scaledScreenParams.zw - 1) * 0.5;
	float rawDepthBL = SAMPLE_TEXTURE2D_X(_CameraDepthTexture, my_point_clamp_sampler, spineNDC.xy + halfTexel * float2(-1, -1)).r;
	float rawDepthTL = SAMPLE_TEXTURE2D_X(_CameraDepthTexture, my_point_clamp_sampler, spineNDC.xy + halfTexel * float2(-1, 1)).r;
	float rawDepthBR = SAMPLE_TEXTURE2D_X(_CameraDepthTexture, my_point_clamp_sampler, spineNDC.xy + halfTexel * float2(1, -1)).r;
	float rawDepthTR = SAMPLE_TEXTURE2D_X(_CameraDepthTexture, my_point_clamp_sampler, spineNDC.xy + halfTexel * float2(1, 1)).r;
	float4 rawDepthGather = 0;
	if (_ProjectionParams.x < 0)
	{
		rawDepthGather = float4(rawDepthTL, rawDepthTR, rawDepthBR, rawDepthBL);
	}
	else
	{
		rawDepthGather = float4(rawDepthBL, rawDepthBR, rawDepthTR, rawDepthTL);
	}
	#endif

	#if !UNITY_REVERSED_Z
	float rawDepth = max(rawDepthGather.x, max(rawDepthGather.y, max(rawDepthGather.z, rawDepthGather.w)));
	#else
	float rawDepth = min(rawDepthGather.x, min(rawDepthGather.y, min(rawDepthGather.z, rawDepthGather.w)));
	#endif

	float sceneZ = (unity_OrthoParams.w == 0) ? LinearEyeDepth(rawDepth, _ZBufferParams) : LinearDepthToEyeDepth(rawDepth);
	float thisZ = - (input.spineVS.z);
	float depthDifference = thisZ - sceneZ;

#ifdef WIREFRAME_CAN_USE_NOPERSPECTIVE
	float2 uv = input.uvAndLengthScale.xy;
	float lengthScale = input.uvAndLengthScale.z;
#else
	float2 uv = input.uvLengthScaleAndClipW.xy / input.uvLengthScaleAndClipW.w;
	float lengthScale = input.uvLengthScaleAndClipW.z / input.uvLengthScaleAndClipW.w;
#endif
	float wireframePerpendicularSignedDistance = (uv.x - 0.5) * _Width;
	float arclength = uv.y * lengthScale;
#if defined(WIREFRAME_WORLD)
	float uDeriv = fwidth(uv.x);
#endif

	_Width *= 1 - smoothstep(_NdcMinMaxCutoffForWidthAndAlpha.x, _NdcMinMaxCutoffForWidthAndAlpha.y, ndcOutsideView);
	#ifdef WIREFRAME_BEHIND_DEPTH_FADE
	float depthFadeFraction = exp(-max(0, depthDifference) / _DepthFadeDistance);
	_Width *= depthFadeFraction;
	#endif

	float dashLengthTotal = _DashLength + _EmptyLength;
	float Radius = _Width * 0.5;//Even if width is larger than dashLength/2, we still want the line width to be what controls the radius
	float dashInputsFromCenter = (frac(arclength / dashLengthTotal) - 0.5) * (dashLengthTotal);
	float wireframeOffset = max(0, abs(wireframePerpendicularSignedDistance));//Note that this should be max(0, wireframeFinal - width + Radius), but here we will just take Radius = width.
#ifdef WIREFRAME_DASH
	float dashInputOffset = max(0, abs(dashInputsFromCenter) -_DashLength * 0.5);//Note that don't add Radius, which makes the rounding cap start at the desired width. This will cause dashes to 'link' together when width is large compared to dash width.
	float sdf = -Radius + sqrt(dashInputOffset*dashInputOffset + wireframeOffset * wireframeOffset);
#else
	float sdf = -Radius + wireframeOffset;
#endif

	float falloffWidth = _FalloffWidth;
#if defined(WIREFRAME_WORLD)
	float sdfWidth = fwidth(sdf);
	falloffWidth *= sdfWidth;
	falloffWidth *= smoothstep(1, 0.5, uDeriv);
#endif
	float wireframeFraction = InverseLerpUnclamped(0, -falloffWidth, sdf);//NB Here, falloff ends at _Width, instead of starting at it.
	#ifdef WIREFRAME_CLIP
	wireframeFraction = wireframeFraction > 0 ? wireframeFraction : wireframeFraction * falloffWidth;
	#endif

#ifdef WIREFRAME_TEXTURE
	float2 uvFinal = float2(uv.x, arclength / _TexLength);//NB When _Width and _TexLength are equal, a square texture has the correct aspect ratio
	float texR = saturate(_WireframeTex.Sample(sampler_linear_repeat, uvFinal).r);
	wireframeFraction = wireframeFraction > 0 ? saturate(wireframeFraction) * texR : wireframeFraction;
#endif

	float alpha = lerp(0, _EdgeColor.a, saturate(wireframeFraction));
#ifdef WIREFRAME_WORLD
	alpha *= smoothstep(4, 1, uDeriv);
#endif
	#ifdef WIREFRAME_BEHIND_DEPTH_FADE
	alpha *= depthFadeFraction;
	#endif

	float depthInFrontBehindFactor = smoothstep(0.00, _InFrontDepthCutoff, depthDifference);
	
	
#ifdef WIREFRAME_CLIP
	#if defined(_WIREFRAME_DEPTH_INFRONT)
		clip(_InFrontDepthCutoff - depthDifference);
	#elif defined(_WIREFRAME_DEPTH_BEHIND)
		clip(depthDifference - _InFrontDepthCutoff);
	#elif defined(_WIREFRAME_DEPTH_ALL)
	//Don't clip in this case
	#endif
#endif

	#if defined(_WIREFRAME_DEPTH_INFRONT)
	alpha *= 1 - depthInFrontBehindFactor;
	#elif defined(_WIREFRAME_DEPTH_BEHIND)
	alpha *= depthInFrontBehindFactor;
	#elif defined(_WIREFRAME_DEPTH_ALL)
	//Don't change alpha in this case
	#endif
	
	alpha *= 1 - smoothstep(_NdcMinMaxCutoffForWidthAndAlpha.z, _NdcMinMaxCutoffForWidthAndAlpha.w, ndcOutsideView);
	
	float4 color = float4(_EdgeColor.rgb, alpha);
	
	#if defined(WIREFRAME_CLIP)
	clip(wireframeFraction + _WireframeCutoff);
	#endif

	return color;
}


#endif